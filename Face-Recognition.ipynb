{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ZipFile('att_faces.zip')\n",
    "file.extractall()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as py \n",
    "folder = 1\n",
    "file = 1\n",
    "data = []\n",
    "#generate data matrix\n",
    "for i in range(1,41):\n",
    "    for j in range(1,11):\n",
    "        data.append(py.imread(\"att_faces/\"+\"s\" + str(i) + \"/\"+str(j)+\".pgm\"))   #append data from the folder path\n",
    "#print(data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the image into vector\n",
    "for i in range(0,400):\n",
    "    data[i] = data[i].reshape(10304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate label vector Y\n",
    "labels = []\n",
    "for i in range(1,41):\n",
    "    for j in range(1,11):\n",
    "       labels.append(i)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(labels)\n",
    "#print(Y)\n",
    "#list(range(0,401,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data to Training Set and testing set\n",
    "D_train = D[list(range(0,400,2))]\n",
    "#print(D_train.shape)\n",
    "Y_train = Y[list(range(0,400,2))]\n",
    "#print(Y_train.shape)\n",
    "D_test = D[list(range(1,400,2))]\n",
    "#print(D_test.shape)\n",
    "Y_test = Y[list(range(1,400,2))]\n",
    "#print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meanVector= D.mean(0)            # compute mean vector\n",
    "#print(meanVector)\n",
    "Z=np.subtract(D, meanVector)     # center the data\n",
    "#print(Z)\n",
    "covM=np.cov(D,rowvar=False,bias=False)  #calculate covariance matrix\n",
    "#print(covM)\n",
    "#print(covM.shape)\n",
    "egValues,egVectors=np.linalg.eigh(covM)   # calculate Eigen vectors and Eigen values\n",
    "#print(egValues)\n",
    "#print(egVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =[0.8,0.85,0.9,0.95]\n",
    "eigPairs = [(np.abs(egValues[i]), egVectors[:,i] )for i in range(len(egValues))] \n",
    "eigPairs.sort(key=lambda x: x[0], reverse=True)\n",
    "#print(eigPairs)\n",
    "toteigValues = sum(egValues)\n",
    "sortedegValues=sorted(egValues, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "#alpha=0.8\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "explainedVariance=0\n",
    "Ur1=eigPairs[0][1].reshape(10304,1)\n",
    "explainedVariance += (sortedegValues[0]/ toteigValues)\n",
    "for i in range(len(egValues)):\n",
    "    if explainedVariance >= 0.8:\n",
    "        break\n",
    "    explainedVariance += (sortedegValues[i+1]/ toteigValues)\n",
    "    Ur1= np.hstack((Ur1,eigPairs[i+1][1].reshape(10304,1)))\n",
    "print(i+1)\n",
    "#print(Ur1)\n",
    "#print(Ur1.shape)\n",
    "\n",
    "#Reducing dimentionality\n",
    "Training_set_Transform = np.dot(D_train,Ur1)\n",
    "Test_set_Transform = np.dot(D_test,Ur1)\n",
    "\n",
    "\n",
    "\n",
    "# instantiate learning model \n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(Training_set_Transform,Y_train)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(Test_set_Transform)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "(200, 10304)\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "#alpha=0.85\n",
    "explainedVariance=0\n",
    "Ur2=eigPairs[0][1].reshape(10304,1)\n",
    "explainedVariance += (sortedegValues[0]/ toteigValues)\n",
    "for i in range(len(sortedegValues)):\n",
    "    if explainedVariance >= 0.85:\n",
    "        break\n",
    "    explainedVariance += (sortedegValues[i+1]/ toteigValues)\n",
    "    Ur2= np.hstack((Ur2,eigPairs[i+1][1].reshape(10304,1)))\n",
    "    #print(explainedVariance)\n",
    "print(i+1)\n",
    "#print(Ur2)\n",
    "#print(Ur2.shape)\n",
    "\n",
    "#Reducing dimentionality\n",
    "Training_set_Transform2 = np.dot(D_train,Ur2)\n",
    "Test_set_Transform2 = np.dot(D_test,Ur2)\n",
    "#Training_set_Transform = Ur1.T.dot(D_train)\n",
    "#Test_set_Transform = Ur1.T.dot(D_test)\n",
    "\n",
    "\n",
    "# instantiate learning model (k = 1)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=1)\n",
    "# fitting the model\n",
    "knn2.fit(Training_set_Transform2,Y_train)\n",
    "\n",
    "# predict the response\n",
    "pred2 = knn2.predict(Test_set_Transform2)\n",
    "print(D_test.shape)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "(200, 10304)\n",
      "Accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "#alpha=0.9\n",
    "explainedVariance=0\n",
    "Ur3=eigPairs[0][1].reshape(10304,1)\n",
    "explainedVariance += (sortedegValues[0]/ toteigValues)\n",
    "for i in range(len(sortedegValues)):\n",
    "    if explainedVariance >= 0.9:\n",
    "        break\n",
    "    explainedVariance += (sortedegValues[i+1]/ toteigValues)\n",
    "    Ur3= np.hstack((Ur3,eigPairs[i+1][1].reshape(10304,1)))\n",
    "    #print(explainedVariance)\n",
    "print(i+1)\n",
    "#print(Ur3)\n",
    "#print(Ur3.shape)\n",
    "#Reducing dimentionality\n",
    "Training_set_Transform3 = np.dot(D_train,Ur3)\n",
    "Test_set_Transform3 = np.dot(D_test,Ur3)\n",
    "#Training_set_Transform = Ur1.T.dot(D_train)\n",
    "#Test_set_Transform = Ur1.T.dot(D_test)\n",
    "\n",
    "\n",
    "# instantiate learning model (k = 1)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# fitting the model\n",
    "knn3.fit(Training_set_Transform3,Y_train)\n",
    "\n",
    "# predict the response\n",
    "pred3 = knn3.predict(Test_set_Transform3)\n",
    "print(D_test.shape)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "(200, 10304)\n",
      "Accuracy: 0.945\n"
     ]
    }
   ],
   "source": [
    "#alpha=0.95\n",
    "explainedVariance=0\n",
    "Ur4=eigPairs[0][1].reshape(10304,1)\n",
    "explainedVariance += (sortedegValues[0]/ toteigValues)\n",
    "for i in range(len(sortedegValues)):\n",
    "    if explainedVariance >= 0.95:\n",
    "        break\n",
    "    explainedVariance += (sortedegValues[i+1]/ toteigValues)\n",
    "    Ur4= np.hstack((Ur4,eigPairs[i+1][1].reshape(10304,1)))\n",
    "    #print(explainedVariance)\n",
    "print(i+1)\n",
    "#print(Ur4)\n",
    "#print(Ur4.shape)\n",
    "#Reducing dimentionality\n",
    "Training_set_Transform4 = np.dot(D_train,Ur4)\n",
    "Test_set_Transform4 = np.dot(D_test,Ur4)\n",
    "#Training_set_Transform = Ur1.T.dot(D_train)\n",
    "#Test_set_Transform = Ur1.T.dot(D_test)\n",
    "\n",
    "\n",
    "# instantiate learning model (k = 1)\n",
    "knn4 = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# fitting the model\n",
    "knn4.fit(Training_set_Transform4,Y_train)\n",
    "\n",
    "# predict the response\n",
    "pred4 = knn4.predict(Test_set_Transform4)\n",
    "print(D_test.shape)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test,pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tunning KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=3)\n",
    "#train model with cv of 5 \n",
    "cv_scores = cross_val_score(knn_cv, D,Y, cv=10)\n",
    "#print each cv score (accuracy) and average them\n",
    "print(cv_scores)\n",
    "#print(cv_scores mean:{}.format(np.mean(cv_scores)))\n",
    "\n",
    "#create new a knn model\n",
    "knn2 = KNeighborsClassifier()\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 30)}\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn2, param_grid,scoring='accuracy',cv=10,n_jobs=-1)\n",
    "print(\"hi\")\n",
    "#fit model to data\n",
    "knn_gscv.fit(D,Y)\n",
    "#check top performing n_neighbors value\n",
    "knn_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold\n",
    "from sklearn.model_selection import KFold\n",
    "kf =KFold(n_splits=10, random_state=None) \n",
    "\n",
    "for train_index, test_index in kf.split(D):\n",
    "      print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_train, X_test = D[train_index], D[test_index] \n",
    "      y_train, y_test = Y[train_index], Y[test_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
